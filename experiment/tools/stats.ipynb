{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "style.use('seaborn-poster') #sets the size of the charts\n",
    "# style.use('ggplot')\n",
    "\n",
    "# Useful directory path.\n",
    "root_dir = f'{os.getcwd()}/../results'\n",
    "graphics_dir = f'{root_dir}/graphics'\n",
    "\n",
    "# GP tools.\n",
    "tools = ('DEAP', 'TensorGP (CPU)', 'TensorGP (GPU)', 'Operon', 'FPGA')\n",
    "\n",
    "# Function sets.\n",
    "function_sets = {\n",
    "    'nicolau_a': (4, 9, 1023, 32),\n",
    "    'nicolau_b': (6, 7, 255, 8),\n",
    "    'nicolau_c': (9, 7, 255, 8)\n",
    "}\n",
    "\n",
    "# Numbers of fitness cases.\n",
    "num_fitness_cases = (10, 100, 1000, 10000, 100000)\n",
    "\n",
    "# Number of programs per size bin.\n",
    "nppsb = 128\n",
    "\n",
    "# Program dictionary.\n",
    "with open(f'{root_dir}/programs/programs.pkl', 'rb') as f:\n",
    "    program_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute some statistics for the set of random programs\n",
    "# generated for each function set.\n",
    "\n",
    "# Total number of nodes for each size bin, for each function set.\n",
    "num_nodes = []\n",
    "\n",
    "for name, (num_functions, max_depth, max_size, bin_size) in (\n",
    "    function_sets.items()):\n",
    "    # For each function set...\n",
    "\n",
    "    # Number of \"size bins.\"\n",
    "    num_size_bins = int(math.ceil(max_size/bin_size))\n",
    "\n",
    "    # List where the `i`-th element, `0 <= i <= max_depth`, \n",
    "    # is to represent the number of instances for depth `i` \n",
    "    # over all random programs (i.e., from all size bins) \n",
    "    # for the function set with name `name`.\n",
    "    depth_counts = [0]*(max_depth+1)\n",
    "\n",
    "    # List where the `i`-th element, `0 <= i <= max_size-1`, \n",
    "    # is to represent the number of instances for size `i+1` \n",
    "    # over all random programs (i.e., from all size bins) \n",
    "    # for the function set with name `name`.\n",
    "    size_counts = [0]*(max_size)\n",
    "\n",
    "    # Lists where the `i`-th element contains the proportion\n",
    "    # of the total number of nodes for size bin `i` that are \n",
    "    # functions/variables/constants/terminals.\n",
    "    function_node_proportions = []\n",
    "    variable_node_proportions = []\n",
    "    constant_node_proportions = []\n",
    "    terminal_node_proportions = []\n",
    "    \n",
    "    # List where the `i`-th element is to represent the \n",
    "    # \"average function value\" for size bin `i`, where \n",
    "    # this value is defined here to be the sum of the \n",
    "    # numbers of instances of each function type, with \n",
    "    # the `i`-th function type (specified by the `function_\n",
    "    # counts` list) multiplied by `i`, all divided by the \n",
    "    # number of function types.\n",
    "    #\n",
    "    # In general, if the numbers of instances of function \n",
    "    # types are uniformly distributed for each size bin, \n",
    "    # the \"average function value\" as defined above should \n",
    "    # be equal to the number of function types minus one,\n",
    "    # divided by 2. Thus, we can check for such uniformity\n",
    "    # for each size bin by inspecting such an average value.\n",
    "    average_function_values = []\n",
    "\n",
    "    # Prepare for sizes related to the function set.\n",
    "    num_nodes.append([])\n",
    "\n",
    "    # Results of chi-square tests for each bin of the function set.\n",
    "    chi_square = [[]]\n",
    "\n",
    "    # Compute the relevant list elements.\n",
    "    for i, (programs, depths, sizes, function_counts, \n",
    "        variable_counts, constant_counts) in enumerate(program_dict[name]\n",
    "            [0:num_size_bins]):\n",
    "\n",
    "        for depth in depths: depth_counts[depth] += 1\n",
    "        for size in sizes: size_counts[size-1] += 1\n",
    "\n",
    "        function_node_sum = sum(function_counts)\n",
    "        variable_node_sum = sum(variable_counts)\n",
    "        constant_node_sum = sum(constant_counts)\n",
    "        terminal_node_sum = variable_node_sum + constant_node_sum\n",
    "        node_sum = function_node_sum + terminal_node_sum\n",
    "\n",
    "        function_node_proportions.append(function_node_sum/node_sum)\n",
    "        variable_node_proportions.append(variable_node_sum/node_sum)\n",
    "        constant_node_proportions.append(constant_node_sum/node_sum)\n",
    "        terminal_node_proportions.append(terminal_node_sum/node_sum)\n",
    " \n",
    "        average_function_value = (0) if (function_node_sum == 0) else (\n",
    "            sum([i*function_counts[i] for i in range(\n",
    "                num_functions)])/function_node_sum)\n",
    "\n",
    "        average_function_values.append(average_function_value)\n",
    "\n",
    "        # Add total number of nodes for the current size bin.\n",
    "        num_nodes[-1].append(sum(sizes))\n",
    "\n",
    "        # P-value for one-way chi-square test, performed for \n",
    "        # each set of function counts.\n",
    "        _, p = stats.chisquare(function_counts)\n",
    "        chi_square[-1].append(p)\n",
    "\n",
    "        print(f'Function counts, bin {i}: {function_counts}')\n",
    "\n",
    "    print(f'Chi-square p-values: {chi_square[-1]}')\n",
    "    print(f'Minimum chi-square p-value: {min(chi_square[-1])}')\n",
    "    print(f'Average chi-square p-value: {np.mean(chi_square[-1])}')\n",
    "\n",
    "    # Compute/plot some relevant statistics for the number \n",
    "    # of instances of each possible program depth.\n",
    "\n",
    "    # print('Program depths: ', depth_counts)\n",
    "    # print('Mean of depth counts: ', np.mean(depth_counts))\n",
    "    # print('Variance of depth counts: ', np.var(depth_counts))\n",
    "    # print('Standard deviation of depth counts: ', np.std(depth_counts))\n",
    "    # print(stats.chisquare(depth_counts))\n",
    "\n",
    "    # Plot bar graph of depth counts.\n",
    "    index = range(0, max_depth+1)\n",
    "    plt.bar(index, depth_counts)\n",
    "    plt.xlabel('Depth')\n",
    "    plt.ylabel('Depth counts')\n",
    "    plt.title('Number of instances of each depth ('+name+')')\n",
    "    plt.savefig(f'{graphics_dir}/{name}/depths.svg')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Compute/plot some relevant statistics for the number \n",
    "    # of instances of each possible program size.\n",
    "\n",
    "    # print('Program sizes: ', size_counts)\n",
    "    # print('Mean of size counts: ', np.mean(size_counts))\n",
    "    # print('Variance of size counts: ', np.var(size_counts))\n",
    "    # print('Standard deviation of size counts: ', np.std(size_counts))\n",
    "    # print(stats.chisquare(size_counts))\n",
    "\n",
    "    # Plot bar graph of size counts.\n",
    "    index = range(1, max_size+1)\n",
    "    plt.bar(index, size_counts)\n",
    "    plt.xlabel('Size')\n",
    "    plt.ylabel('Size counts')\n",
    "    plt.title('Number of instances of each size ('+name+')')\n",
    "    plt.savefig(f'{graphics_dir}/{name}/sizes.svg')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Compute/plot some relevant statistics for the average\n",
    "    # function values.\n",
    "\n",
    "    # print('Average function values: ', average_function_values)\n",
    "    # print('Mean of average function values: ', \n",
    "    #     np.mean(average_function_values))\n",
    "    # print('Variance of average function values: ', \n",
    "    #     np.var(average_function_values))\n",
    "    # print('Standard deviation of average function values: ', \n",
    "    #     np.std(average_function_values))\n",
    "    # print(f'\\n\\nAverage function values: {average_function_values}\\n\\n')\n",
    "    # print(stats.chisquare(average_function_values))\n",
    "\n",
    "    # Plot bar graph of average function values.\n",
    "    index = range(1, num_size_bins+1)\n",
    "\n",
    "    #log_approx = [4*(1/log(max_size,2))*log(max_size/x,2) + \n",
    "    #    10.5*(1/log(max_size,2))*log(x, 2) for x in index]\n",
    "\n",
    "    #plt.plot(index, log_approx)\n",
    "    plt.bar(index, average_function_values)\n",
    "\n",
    "    plt.xlabel('Size bin number')\n",
    "    plt.ylabel('Average function value')\n",
    "    plt.title('Average function value, per size bin ('+name+')')\n",
    "    plt.savefig(f'{graphics_dir}/{name}/average_function_values.svg')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Compute/plot some relevant statistics for proportions\n",
    "    # of the total number of nodes with particular node types.\n",
    "\n",
    "    # print('Function node proportions: ', function_node_proportions)\n",
    "    # print('Terminal node proportions: ', terminal_node_proportions)\n",
    "    # print('Variable node proportions: ', variable_node_proportions)\n",
    "    # print('Constant node proportions: ', constant_node_proportions)\n",
    "\n",
    "\n",
    "    # Plot bar graph of function counts.\n",
    "    index = range(1, num_size_bins+1)\n",
    "    plt.bar(index, function_node_proportions, \n",
    "        label='Function node proportions')\n",
    "    plt.bar(index, terminal_node_proportions, \n",
    "        label='Terminal node proportions')\n",
    "    plt.bar(index, variable_node_proportions, \n",
    "        label='Variable node proportions')\n",
    "    plt.bar(index, constant_node_proportions, \n",
    "        label='Constant node proportions')\n",
    "    plt.xlabel('Size bin number')\n",
    "    plt.ylabel('Node type proportions')\n",
    "    plt.title('Proportions of each node type, per size bin ('+name+')')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig(f'{graphics_dir}/{name}/node_proportions.svg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of *median average runtimes* for each size bin,\n",
    "# for each number of fitness cases, for each function set,\n",
    "# for each tool.\n",
    "avg_med_avg_runtimes = []\n",
    "\n",
    "# Median of *median average runtimes* for each size bin,\n",
    "# for each number of fitness cases, for each function set,\n",
    "# for each tool.\n",
    "med_med_avg_runtimes = []\n",
    "\n",
    "# Minimum of *median average runtimes* for each size bin,\n",
    "# for each number of fitness cases, for each function set,\n",
    "# for each tool.\n",
    "min_med_avg_runtimes = []\n",
    "\n",
    "# Maximum of *median average runtimes* for each size bin,\n",
    "# for each number of fitness cases, for each function set,\n",
    "# for each tool.\n",
    "max_med_avg_runtimes = []\n",
    "\n",
    "# Standard deviation of *median average runtimes* for each size \n",
    "# bin, for each number of fitness cases, for each function set,\n",
    "# for each tool.\n",
    "std_dev_med_avg_runtimes = []\n",
    "\n",
    "# Interquartile range of *median average runtimes* for each size \n",
    "# bin, for each number of fitness cases, for each function set,\n",
    "# for each tool.\n",
    "iqr_med_avg_runtimes = []\n",
    "\n",
    "# Median node evaluations per second (NEPS) from *median average\n",
    "# runtimes* for each size bin, for each number of fitness cases, \n",
    "# for each function set, for each tool.\n",
    "med_neps = []\n",
    "\n",
    "# Median of median node evaluations per second (NEPS) for each \n",
    "# size bin, for each number of fitness cases, for each function \n",
    "# set, for each tool.\n",
    "med_med_neps = []\n",
    "\n",
    "# Interquartile range of median node evaluations per second (NEPS) \n",
    "# for each size bin, for each number of fitness cases, for each \n",
    "# function set, for each tool.\n",
    "iqr_med_neps = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "\n",
    "# Compute statistics for DEAP.\n",
    "\n",
    "with open(f'{root_dir}/results_deap.pkl', 'rb') as f:\n",
    "    _, med_avg_runtimes = pickle.load(f)\n",
    "\n",
    "# Prepare for statistics related to the tool.\n",
    "avg_med_avg_runtimes.append([])\n",
    "med_med_avg_runtimes.append([])\n",
    "min_med_avg_runtimes.append([])\n",
    "max_med_avg_runtimes.append([])\n",
    "std_dev_med_avg_runtimes.append([])\n",
    "iqr_med_avg_runtimes.append([])\n",
    "med_neps.append([])\n",
    "med_med_neps.append([])\n",
    "iqr_med_neps.append([])\n",
    "\n",
    "for i, (name, (num_functions, max_depth, max_size, bin_size)) in enumerate(\n",
    "    function_sets.items()):\n",
    "    # For each function set...\n",
    "    print(f'For function set `{name}`...')\n",
    "\n",
    "    # Number of \"size bins.\"\n",
    "    num_size_bins = int(math.ceil(max_size/bin_size))\n",
    "\n",
    "    # Prepare for statistics related to the function set.\n",
    "    avg_med_avg_runtimes[-1].append([])\n",
    "    med_med_avg_runtimes[-1].append([])\n",
    "    min_med_avg_runtimes[-1].append([])\n",
    "    max_med_avg_runtimes[-1].append([])\n",
    "    std_dev_med_avg_runtimes[-1].append([])\n",
    "    iqr_med_avg_runtimes[-1].append([])\n",
    "    med_neps[-1].append([])\n",
    "    med_med_neps[-1].append([])\n",
    "    iqr_med_neps[-1].append([])\n",
    "\n",
    "    for j, nfc in enumerate(num_fitness_cases):\n",
    "        # For each number of fitness cases...\n",
    "        print(f'For number of fitness cases `{nfc}`...')\n",
    "\n",
    "        # Average of *median average runtimes* for each size bin,\n",
    "        # relevant to the number of fitness cases.\n",
    "        avg_med_avg_runtimes[-1][-1].append(\n",
    "            [np.mean(med_avg_runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Averages of median average runtimes:', \n",
    "            avg_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Median of *median average runtimes* for each size bin,\n",
    "        # relevant to the number of fitness cases.\n",
    "        med_med_avg_runtimes[-1][-1].append(\n",
    "            [np.median(med_avg_runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Medians of median average runtimes:', \n",
    "            med_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Minimum of *median average runtimes* for each size bin,\n",
    "        # relevant to the number of fitness cases.\n",
    "        min_med_avg_runtimes[-1][-1].append(\n",
    "            [min(med_avg_runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Minimums of median average runtimes:', \n",
    "            min_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Maximum of *median average runtimes* for each size bin,\n",
    "        # relevant to the number of fitness cases.\n",
    "        max_med_avg_runtimes[-1][-1].append(\n",
    "            [max(med_avg_runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Maximums of median average runtimes:', \n",
    "            max_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Standard deviation of *median average runtimes* for each \n",
    "        # size bin, relevant to the number of fitness cases.\n",
    "        std_dev_med_avg_runtimes[-1][-1].append(\n",
    "            [np.std(med_avg_runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Standard deviations of median average runtimes:', \n",
    "            std_dev_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Interquartile range of *median average runtimes* for each \n",
    "        # size bin, relevant to the number of fitness cases.\n",
    "        iqr_med_avg_runtimes[-1][-1].append(\n",
    "            [stats.iqr(med_avg_runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Interquartile range of median average runtimes:', \n",
    "            iqr_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n\\n')\n",
    "\n",
    "        print('Number of nodes per size bin:', num_nodes[i])\n",
    "\n",
    "        # Number of node evaluations per size bin.\n",
    "        num_evals = [(n * nfc) for n in num_nodes[i]]\n",
    "\n",
    "        print('Number of node evaluations per size bin:', num_evals)\n",
    "\n",
    "        # Median node evaluations per second (NEPS) from *median \n",
    "        # average runtimes*, for each size bin, relevant to the \n",
    "        # number of fitness cases.\n",
    "        med_neps[-1][-1].append([[num_evals_ / med_avg_runtime\n",
    "            for med_avg_runtime in med_avg_runtimes[i][j][k]]\n",
    "            for k, num_evals_ in enumerate(num_evals)])\n",
    "        print('Median node evaluations per second:', med_neps[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Median node evaluations per second (NEPS) of *median \n",
    "        # average runtimes*, for each size bin, relevant to the \n",
    "        # number of fitness cases.\n",
    "        med_med_neps[-1][-1].append([np.median(med_neps_)\n",
    "            for med_neps_ in med_neps[-1][-1][-1]])\n",
    "        print('Median of median node evaluations per second:', \n",
    "            med_med_neps[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Interquartile range of median node evaluations per second \n",
    "        # (NEPS), for each size bin, relevant to the number of fitness \n",
    "        # cases.\n",
    "        iqr_med_neps[-1][-1].append([stats.iqr(med_neps_)\n",
    "            for med_neps_ in med_neps[-1][-1][-1]])\n",
    "        print('Interquartile range of median node evaluations per second:', \n",
    "            iqr_med_neps[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Minimum median NEPS value.\n",
    "        print('Minimum median NEPS value', min(med_med_neps[-1][-1][-1]))\n",
    "\n",
    "        # Maximum median NEPS value.\n",
    "        print('Maximum median NEPS value', max(med_med_neps[-1][-1][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "\n",
    "# Compute statistics for TensorGP.\n",
    "\n",
    "with open(f'{root_dir}/results_tensorgp.pkl', 'rb') as f:\n",
    "    med_avg_runtimes = pickle.load(f)\n",
    "\n",
    "for i, device in enumerate(('CPU', 'GPU')):\n",
    "    # For each device...\n",
    "    print(f'For device `{device}`...')\n",
    "\n",
    "    # Prepare for statistics related to the tool.\n",
    "    avg_med_avg_runtimes.append([])\n",
    "    med_med_avg_runtimes.append([])\n",
    "    min_med_avg_runtimes.append([])\n",
    "    max_med_avg_runtimes.append([])\n",
    "    std_dev_med_avg_runtimes.append([])\n",
    "    iqr_med_avg_runtimes.append([])\n",
    "    med_neps.append([])\n",
    "    med_med_neps.append([])\n",
    "    iqr_med_neps.append([])\n",
    "\n",
    "    for j, (name, (num_functions, max_depth, max_size, bin_size)) in enumerate(\n",
    "        function_sets.items()):\n",
    "        # For each function set...\n",
    "        print(f'For function set `{name}`...')\n",
    "\n",
    "        # Number of \"size bins.\"\n",
    "        num_size_bins = int(math.ceil(max_size/bin_size))\n",
    "\n",
    "        # Prepare for statistics related to the function set.\n",
    "        avg_med_avg_runtimes[-1].append([])\n",
    "        med_med_avg_runtimes[-1].append([])\n",
    "        min_med_avg_runtimes[-1].append([])\n",
    "        max_med_avg_runtimes[-1].append([])\n",
    "        std_dev_med_avg_runtimes[-1].append([])\n",
    "        iqr_med_avg_runtimes[-1].append([])\n",
    "        med_neps[-1].append([])\n",
    "        med_med_neps[-1].append([])\n",
    "        iqr_med_neps[-1].append([])\n",
    "\n",
    "        for k, nfc in enumerate(num_fitness_cases):\n",
    "            # For each number of fitness cases...\n",
    "            print(f'For number of fitness cases `{nfc}`...')\n",
    "\n",
    "\n",
    "            # Average of *median average runtimes* for each size bin,\n",
    "            # relevant to the number of fitness cases.\n",
    "            avg_med_avg_runtimes[-1][-1].append(\n",
    "                [np.mean(med_avg_runtimes[i][j][k][m]) \n",
    "                for m in range(num_size_bins)])\n",
    "            print('Averages of median average runtimes:', \n",
    "                avg_med_avg_runtimes[-1][-1][-1])\n",
    "            print('\\n')\n",
    "\n",
    "            # Median of *median average runtimes* for each size bin,\n",
    "            # relevant to the number of fitness cases.\n",
    "            med_med_avg_runtimes[-1][-1].append(\n",
    "                [np.median(med_avg_runtimes[i][j][k][m]) \n",
    "                for m in range(num_size_bins)])\n",
    "            print('Medians of median average runtimes:', \n",
    "                med_med_avg_runtimes[-1][-1][-1])\n",
    "            print('\\n')\n",
    "\n",
    "            # Minimum of *median average runtimes* for each size bin,\n",
    "            # relevant to the number of fitness cases.\n",
    "            min_med_avg_runtimes[-1][-1].append(\n",
    "                [min(med_avg_runtimes[i][j][k][m]) \n",
    "                for m in range(num_size_bins)])\n",
    "            print('Minimums of median average runtimes:', \n",
    "                min_med_avg_runtimes[-1][-1][-1])\n",
    "            print('\\n')\n",
    "\n",
    "            # Maximum of *median average runtimes* for each size bin,\n",
    "            # relevant to the number of fitness cases.\n",
    "            max_med_avg_runtimes[-1][-1].append(\n",
    "                [max(med_avg_runtimes[i][j][k][m]) \n",
    "                for m in range(num_size_bins)])\n",
    "            print('Maximums of median average runtimes:', \n",
    "                max_med_avg_runtimes[-1][-1][-1])\n",
    "            print('\\n')\n",
    "\n",
    "            # Standard deviation of *median average runtimes* for each size bin,\n",
    "            # relevant to the number of fitness cases.\n",
    "            std_dev_med_avg_runtimes[-1][-1].append(\n",
    "                [np.std(med_avg_runtimes[i][j][k][m]) \n",
    "                for m in range(num_size_bins)])\n",
    "            print('Standard deviations of median average runtimes:', \n",
    "                std_dev_med_avg_runtimes[-1][-1][-1])\n",
    "            print('\\n')\n",
    "\n",
    "            # Interquartile range of *median average runtimes* for each size bin,\n",
    "            # relevant to the number of fitness cases.\n",
    "            iqr_med_avg_runtimes[-1][-1].append(\n",
    "                [stats.iqr(med_avg_runtimes[i][j][k][m]) \n",
    "                for m in range(num_size_bins)])\n",
    "            print('Interquartile range of median average runtimes:', \n",
    "                iqr_med_avg_runtimes[-1][-1][-1])\n",
    "            print('\\n\\n')\n",
    "\n",
    "            print('Number of nodes per size bin:', num_nodes[j])\n",
    "\n",
    "            # Number of node evaluations per size bin.\n",
    "            num_evals = [(n * nfc) for n in num_nodes[j]]\n",
    "\n",
    "            print('Number of node evaluations per size bin:', num_evals)\n",
    "\n",
    "            # Median node evaluations per second (NEPS) from *median \n",
    "            # average runtimes*, for each size bin, relevant to the \n",
    "            # number of fitness cases.\n",
    "            med_neps[-1][-1].append([[num_evals_ / med_avg_runtime\n",
    "                for med_avg_runtime in med_avg_runtimes[i][j][k][m]]\n",
    "                for m, num_evals_ in enumerate(num_evals)])\n",
    "            print('Median node evaluations per second:', \n",
    "                med_neps[-1][-1][-1])\n",
    "            print('\\n')\n",
    "\n",
    "            # Median node evaluations per second (NEPS) of *median \n",
    "            # average runtimes*, for each size bin, relevant to the \n",
    "            # number of fitness cases.\n",
    "            med_med_neps[-1][-1].append([np.median(med_neps_) \n",
    "                for med_neps_ in med_neps[-1][-1][-1]])\n",
    "            print('Median of median node evaluations per second:', \n",
    "                med_med_neps[-1][-1][-1])\n",
    "            print('\\n')\n",
    "\n",
    "            # Interquartile range of median node evaluations per \n",
    "            # second (NEPS), for each size bin, relevant to the number \n",
    "            # of fitness cases.\n",
    "            iqr_med_neps[-1][-1].append([stats.iqr(med_neps_) \n",
    "                for med_neps_ in med_neps[-1][-1][-1]])\n",
    "            print('Interquartile range of median node evaluations per second:', \n",
    "                iqr_med_neps[-1][-1][-1])\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "\n",
    "# Compute statistics for Operon.\n",
    "\n",
    "# Read in the median average runtime results from some \n",
    "# CSV files, and convert into another useful format.\n",
    "med_avg_runtimes = []\n",
    "\n",
    "for name, (num_functions, max_depth, \n",
    "        max_size, bin_size) in function_sets.items():\n",
    "    \n",
    "    # Number of \"size bins.\"\n",
    "    num_size_bins = int(math.ceil(max_size/bin_size))\n",
    "\n",
    "    # Prepare for statistics relevant to the function set.\n",
    "    med_avg_runtimes.append([])\n",
    "\n",
    "    with open(f'{root_dir}/results_operon_{name}.csv', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for nfc in num_fitness_cases:\n",
    "        # Prepare for statistics relevant to the number\n",
    "        # of fitness cases.\n",
    "        med_avg_runtimes[-1].append([[] for _ in range(num_size_bins)])\n",
    "\n",
    "        # Offset into the lines list.\n",
    "        i = (int(math.log(nfc, 10)) - 1) * num_size_bins\n",
    "\n",
    "        for j in range(1, num_size_bins + 1):\n",
    "            # Number of decimal digits needed to represent `j`.\n",
    "            d = int(math.ceil(math.log(j + 1, 10)))\n",
    "\n",
    "            # String representing median average runtimes\n",
    "            # for bin `j`, in terms of microseconds.\n",
    "            runtimes_str = ''.join(lines[i+j-1].split())[(5+d):]\n",
    "\n",
    "            # Median average runtimes for bin `j`, in terms\n",
    "            # of seconds.\n",
    "            runtimes = [float(t)/(10**6) for t in runtimes_str.split(',')]\n",
    "\n",
    "            med_avg_runtimes[-1][-1][j-1] = runtimes\n",
    "\n",
    "# Prepare for statistics related to the tool.\n",
    "avg_med_avg_runtimes.append([])\n",
    "med_med_avg_runtimes.append([])\n",
    "min_med_avg_runtimes.append([])\n",
    "max_med_avg_runtimes.append([])\n",
    "std_dev_med_avg_runtimes.append([])\n",
    "iqr_med_avg_runtimes.append([])\n",
    "med_neps.append([])\n",
    "med_med_neps.append([])\n",
    "iqr_med_neps.append([])\n",
    "\n",
    "for i, (name, (num_functions, max_depth, max_size, bin_size)) in enumerate(\n",
    "    function_sets.items()):\n",
    "    # For each function set...\n",
    "    print(f'For function set `{name}`...')\n",
    "\n",
    "    # Number of \"size bins.\"\n",
    "    num_size_bins = int(math.ceil(max_size/bin_size))\n",
    "\n",
    "    # Prepare for statistics related to the function set.\n",
    "    avg_med_avg_runtimes[-1].append([])\n",
    "    med_med_avg_runtimes[-1].append([])\n",
    "    min_med_avg_runtimes[-1].append([])\n",
    "    max_med_avg_runtimes[-1].append([])\n",
    "    std_dev_med_avg_runtimes[-1].append([])\n",
    "    iqr_med_avg_runtimes[-1].append([])\n",
    "    med_neps[-1].append([])\n",
    "    med_med_neps[-1].append([])\n",
    "    iqr_med_neps[-1].append([])\n",
    "\n",
    "    for j, nfc in enumerate(num_fitness_cases):\n",
    "        # For each number of fitness cases...\n",
    "        print(f'For number of fitness cases `{nfc}`...')\n",
    "\n",
    "        # Average of *median average runtimes* for each size bin,\n",
    "        # relevant to the number of fitness cases.\n",
    "        avg_med_avg_runtimes[-1][-1].append(\n",
    "            [np.mean(med_avg_runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Averages of median average runtimes:', \n",
    "            avg_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Median of *median average runtimes* for each size bin,\n",
    "        # relevant to the number of fitness cases.\n",
    "        med_med_avg_runtimes[-1][-1].append(\n",
    "            [np.median(med_avg_runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Medians of median average runtimes:', \n",
    "            med_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Minimum of *median average runtimes* for each size bin,\n",
    "        # relevant to the number of fitness cases.\n",
    "        min_med_avg_runtimes[-1][-1].append(\n",
    "            [min(med_avg_runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Minimums of median average runtimes:', \n",
    "            min_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Maximum of *median average runtimes* for each size bin,\n",
    "        # relevant to the number of fitness cases.\n",
    "        max_med_avg_runtimes[-1][-1].append(\n",
    "            [max(med_avg_runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Maximums of median average runtimes:', \n",
    "            max_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Standard deviation of *median average runtimes* for each size bin,\n",
    "        # relevant to the number of fitness cases.\n",
    "        std_dev_med_avg_runtimes[-1][-1].append(\n",
    "            [np.std(med_avg_runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Standard deviations of median average runtimes:', \n",
    "            std_dev_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Interquartile range of *median average runtimes* for each size bin,\n",
    "        # relevant to the number of fitness cases.\n",
    "        iqr_med_avg_runtimes[-1][-1].append(\n",
    "            [stats.iqr(med_avg_runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Interquartile range of median average runtimes:', \n",
    "            iqr_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n\\n')\n",
    "\n",
    "        print('Number of nodes per size bin:', num_nodes[i])\n",
    "\n",
    "        # Number of node evaluations per size bin.\n",
    "        num_evals = [(n * nfc) for n in num_nodes[i]]\n",
    "\n",
    "        print('Number of node evaluations per size bin:', num_evals)\n",
    "\n",
    "        # Median node evaluations per second (NEPS) from *median \n",
    "        # average runtimes*, for each size bin, relevant to the \n",
    "        # number of fitness cases.\n",
    "        med_neps[-1][-1].append([[num_evals_ / med_avg_runtime\n",
    "            for med_avg_runtime in med_avg_runtimes[i][j][k]]\n",
    "            for k, num_evals_ in enumerate(num_evals)])\n",
    "        print('Median node evaluations per second:', med_neps[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Median node evaluations per second (NEPS) of *median \n",
    "        # average runtimes*, for each size bin, relevant to the \n",
    "        # number of fitness cases.\n",
    "        med_med_neps[-1][-1].append([np.median(med_neps_)\n",
    "            for med_neps_ in med_neps[-1][-1][-1]])\n",
    "        print('Median of median node evaluations per second:', \n",
    "            med_med_neps[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Interquartile range of median node evaluations per second \n",
    "        # (NEPS), for each size bin, relevant to the number of fitness \n",
    "        # cases.\n",
    "        iqr_med_neps[-1][-1].append([stats.iqr(med_neps_)\n",
    "            for med_neps_ in med_neps[-1][-1][-1]])\n",
    "        print('Interquartile range of median node evaluations per second:', \n",
    "            iqr_med_neps[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Minimum median NEPS value.\n",
    "        print('Minimum median NEPS value', min(med_med_neps[-1][-1][-1]))\n",
    "\n",
    "        # Maximum median NEPS value.\n",
    "        print('Maximum median NEPS value', max(med_med_neps[-1][-1][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "\n",
    "# Compute statistics for FPGA.\n",
    "\n",
    "# Runtimes for FPGA.\n",
    "runtimes = []\n",
    "\n",
    "for name, (num_functions, max_depth, \n",
    "        max_size, bin_size) in function_sets.items():\n",
    "    \n",
    "    # Number of \"size bins.\"\n",
    "    num_size_bins = int(math.ceil(max_size/bin_size))\n",
    "\n",
    "    # Prepare for statistics relevant to the function set.\n",
    "    runtimes.append([])\n",
    "\n",
    "    for nfc in num_fitness_cases:\n",
    "        with open(f'{root_dir}/performance_counts/{name}/{nfc}.txt', 'r') as f:\n",
    "            # Lines of the current file.\n",
    "            lines = f.readlines()\n",
    "\n",
    "            # Clock frequency for specified run.\n",
    "            clock_freq = float(lines[0])*1e6\n",
    "\n",
    "            # Runtimes relevant to the number of fitness cases.\n",
    "            runtimes[-1].append([[float(lines[i])/clock_freq] \n",
    "                for i in range(1, num_size_bins+1)])\n",
    "\n",
    "# Prepare for statistics related to the tool.\n",
    "avg_med_avg_runtimes.append([])\n",
    "med_med_avg_runtimes.append([])\n",
    "min_med_avg_runtimes.append([])\n",
    "max_med_avg_runtimes.append([])\n",
    "std_dev_med_avg_runtimes.append([])\n",
    "iqr_med_avg_runtimes.append([])\n",
    "med_neps.append([])\n",
    "med_med_neps.append([])\n",
    "iqr_med_neps.append([])\n",
    "\n",
    "for i, (name, (num_functions, max_depth, max_size, bin_size)) in enumerate(\n",
    "    function_sets.items()):\n",
    "    # For each function set...\n",
    "    print(f'For function set `{name}`...')\n",
    "\n",
    "    # Number of \"size bins.\"\n",
    "    num_size_bins = int(math.ceil(max_size/bin_size))\n",
    "\n",
    "    # Prepare for statistics related to the function set.\n",
    "    avg_med_avg_runtimes[-1].append([])\n",
    "    med_med_avg_runtimes[-1].append([])\n",
    "    min_med_avg_runtimes[-1].append([])\n",
    "    max_med_avg_runtimes[-1].append([])\n",
    "    std_dev_med_avg_runtimes[-1].append([])\n",
    "    iqr_med_avg_runtimes[-1].append([])\n",
    "    med_neps[-1].append([])\n",
    "    med_med_neps[-1].append([])\n",
    "    iqr_med_neps[-1].append([])\n",
    "\n",
    "    for j, nfc in enumerate(num_fitness_cases):\n",
    "        # For each number of fitness cases...\n",
    "        print(f'For number of fitness cases `{nfc}`...')\n",
    "\n",
    "        # Average of *median average runtimes* for each size bin,\n",
    "        # relevant to the number of fitness cases.\n",
    "        avg_med_avg_runtimes[-1][-1].append(\n",
    "            [np.mean(runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Averages of median average runtimes:', \n",
    "            avg_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Median of *median average runtimes* for each size bin,\n",
    "        # relevant to the number of fitness cases.\n",
    "        med_med_avg_runtimes[-1][-1].append(\n",
    "            [np.median(runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Medians of median average runtimes:', \n",
    "            med_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Minimum of *median average runtimes* for each size bin,\n",
    "        # relevant to the number of fitness cases.\n",
    "        min_med_avg_runtimes[-1][-1].append(\n",
    "            [min(runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Minimums of median average runtimes:', \n",
    "            min_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Maximum of *median average runtimes* for each size bin,\n",
    "        # relevant to the number of fitness cases.\n",
    "        max_med_avg_runtimes[-1][-1].append(\n",
    "            [max(runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Maximums of median average runtimes:', \n",
    "            max_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Standard deviation of *median average runtimes* for each size bin,\n",
    "        # relevant to the number of fitness cases.\n",
    "        std_dev_med_avg_runtimes[-1][-1].append(\n",
    "            [np.std(runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Standard deviations of median average runtimes:', \n",
    "            std_dev_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Interquartile range of *median average runtimes* for each size bin,\n",
    "        # relevant to the number of fitness cases.\n",
    "        iqr_med_avg_runtimes[-1][-1].append(\n",
    "            [stats.iqr(runtimes[i][j][k]) \n",
    "            for k in range(num_size_bins)])\n",
    "        print('Interquartile range of median average runtimes:', \n",
    "            iqr_med_avg_runtimes[-1][-1][-1])\n",
    "        print('\\n\\n')\n",
    "\n",
    "        print('Number of nodes per size bin:', num_nodes[i])\n",
    "\n",
    "        # Number of node evaluations per size bin.\n",
    "        num_evals = [(n * nfc) for n in num_nodes[i]]\n",
    "\n",
    "        print('Number of node evaluations per size bin:', num_evals)\n",
    "\n",
    "        # Median node evaluations per second (NEPS) from *median \n",
    "        # average runtimes*, for each size bin, relevant to the \n",
    "        # number of fitness cases.\n",
    "        med_neps[-1][-1].append([[num_evals_ / runtime\n",
    "            for runtime in runtimes[i][j][k]]\n",
    "            for k, num_evals_ in enumerate(num_evals)])\n",
    "        print('Median node evaluations per second:', med_neps[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Median node evaluations per second (NEPS) of *median \n",
    "        # average runtimes*, for each size bin, relevant to the \n",
    "        # number of fitness cases.\n",
    "        med_med_neps[-1][-1].append([np.median(med_neps_)\n",
    "            for med_neps_ in med_neps[-1][-1][-1]])\n",
    "        print('Median of median node evaluations per second:', \n",
    "            med_med_neps[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Interquartile range of median node evaluations per second \n",
    "        # (NEPS), for each size bin, relevant to the number of fitness \n",
    "        # cases.\n",
    "        iqr_med_neps[-1][-1].append([stats.iqr(med_neps_)\n",
    "            for med_neps_ in med_neps[-1][-1][-1]])\n",
    "        print('Interquartile range of median node evaluations per second:', \n",
    "            iqr_med_neps[-1][-1][-1])\n",
    "        print('\\n')\n",
    "\n",
    "        # Minimum median NEPS value.\n",
    "        print('Minimum median NEPS value', min(med_med_neps[-1][-1][-1]))\n",
    "\n",
    "        # Maximum median NEPS value.\n",
    "        print('Maximum median NEPS value', max(med_med_neps[-1][-1][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot graph of median average runtimes for each tool, \n",
    "# # for each number of fitness cases, for each function set.\n",
    "# for i, (name, (_, _, max_size, bin_size)) in enumerate(\n",
    "#     function_sets.items()):\n",
    "\n",
    "#     # Number of size bins.\n",
    "#     num_size_bins = int(math.ceil(max_size/bin_size))\n",
    "\n",
    "#     # Index range for plot.\n",
    "#     index = [(bin_size * i) for i in range(1, num_size_bins+1)]\n",
    "\n",
    "#     for j, nfc in enumerate(num_fitness_cases):\n",
    "#         for t, tool in enumerate(tools):\n",
    "#             x = index\n",
    "#             y = med_med_avg_runtimes[t][i][j]\n",
    "#             iqr = iqr_med_avg_runtimes[t][i][j]\n",
    "#             # max_iqr_percentage = [\n",
    "#             lower_bound = [y_ - iqr_ for y_, iqr_ in zip(y, iqr)]\n",
    "#             upper_bound = [y_ + iqr_ for y_, iqr_ in zip(y, iqr)]\n",
    "#             plt.plot(x, y, label=f'{tool}')\n",
    "#             plt.fill_between(x, lower_bound, upper_bound, color='bisque')\n",
    "#         plt.xlabel('Maximum program size (bin number)')\n",
    "#         # plt.xticks(index, [str(size) for size in program_sizes[i]])\n",
    "#         # plt.locator_params(axis='x', nbins=15)\n",
    "#         plt.ylabel('Median average runtime')\n",
    "#         plt.yscale('log')\n",
    "#         plt.title(\n",
    "#             f'Median Average Runtime vs. Max. Program Size '\n",
    "#             f'({nfc} f.c., {name})')\n",
    "#         plt.legend(loc='upper left')\n",
    "#         plt.savefig(f'{graphics_dir}/{name}/median_avg_runtime_{nfc}.svg')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ('tab:cyan', 'tab:purple', 'tab:blue', 'tab:green', 'tab:red')\n",
    "markers = ('X', '^', '.', 'd', '*')\n",
    "marker_sizes = (6, 4, 8, 5, 9)\n",
    "# fill_between = (True, True, True, True, False)\n",
    "print_legend = ((True, False, False, False, False),\n",
    "                (False, False, False, False, False),\n",
    "                (False, False, False, False, False))\n",
    "# print_function_set = ('nicolau_a', 'nicolau_b')\n",
    "# print_nfc = (10, 100000)\n",
    "scale_text_x = ((205, 205, 205, 205, 205),\n",
    "                (52, 52, 52, 52, 52),\n",
    "                (25, 25, 25, 25, 25))\n",
    "scale_text_y = ((0.5e9, 0.5e9, 0.5e9, 1.25e9, 6e8),\n",
    "                (0.5e9, 0.5e9, 0.5e9, 1.25e9, 6e8),\n",
    "                (0.45e9, 0.5e9, 0.5e9, 1.25e9, 5.5e8))\n",
    "                \n",
    "# median_runtimes = []\n",
    "average_neps = []\n",
    "median_neps = []\n",
    "\n",
    "all_neps = [[], [], [], [], []]\n",
    "\n",
    "# Plot graph of median node evaluations per second for each tool, \n",
    "# for each number of fitness cases, for each function set.\n",
    "for i, (name, (_, _, max_size, bin_size)) in enumerate(\n",
    "    function_sets.items()):\n",
    "\n",
    "    # Prepare for average/median NEPS values for each number \n",
    "    # of fitness cases and each tool, for the current function set.\n",
    "    # average_neps.append([[0]*5]*5)\n",
    "    # median_neps.append([[0]*5]*5)\n",
    "    # median_runtimes.append([])\n",
    "    average_neps.append([])\n",
    "    median_neps.append([])\n",
    "\n",
    "    # Number of size bins.\n",
    "    num_size_bins = int(math.ceil(max_size/bin_size))\n",
    "\n",
    "    # Index range for plot.\n",
    "    index = [(bin_size * i) for i in range(1, num_size_bins+1)]\n",
    "    index_ = [i for i in range(1, num_size_bins+1)]\n",
    "\n",
    "    for j, nfc in enumerate(num_fitness_cases):\n",
    "        # median_runtimes[-1].append([])\n",
    "        average_neps[-1].append([])\n",
    "        median_neps[-1].append([])\n",
    "\n",
    "        for t, tool in enumerate(tools):\n",
    "            # median_runtimes[-1][-1].append([])\n",
    "            average_neps[-1][-1].append([])\n",
    "            median_neps[-1][-1].append([])\n",
    "\n",
    "            x = index\n",
    "            y = med_med_neps[t][i][j]\n",
    "            # t = med_med_avg_runtimes[t][i][j]\n",
    "            \n",
    "            iqr = iqr_med_neps[t][i][j]\n",
    "            lower_bound = [y_ - iqr_ for y_, iqr_ in zip(y, iqr)]\n",
    "            upper_bound = [y_ + iqr_ for y_, iqr_ in zip(y, iqr)]\n",
    "\n",
    "            # median_runtimes[-1][-1][-1] = np.median(t)\n",
    "            average_neps[-1][-1][-1] = np.mean(y)\n",
    "            median_neps[-1][-1][-1] = np.median(y)\n",
    "\n",
    "            for neps in y:\n",
    "                all_neps[t].append(neps)\n",
    "\n",
    "            plt.plot(\n",
    "                x, y, label=f'{tool}', markerfacecolor=colors[t], \n",
    "                marker=markers[t], markersize=12, color='black', linewidth=0.1)\n",
    "            plt.axhline(y=1e9, color='gray', linestyle='dashed')\n",
    "            plt.fill_between(\n",
    "                x, lower_bound, upper_bound, interpolate=True, \n",
    "                color='cornsilk')\n",
    "            # plt.fill_between(\n",
    "            #     x, y, where=y<=d, interpolate=True, color='red')\n",
    "\n",
    "\n",
    "        plt.text(\n",
    "            scale_text_x[i][j], scale_text_y[i][j], '$10^9$ for scale', \n",
    "            weight='normal', fontsize = 11)\n",
    "\n",
    "        plt.xlabel('Bin number, maximum program size', fontsize=14)\n",
    "        plt.xticks(index, [f'{str(i_)}, {str(i)}' \n",
    "            for i, i_ in zip(index, index_)], fontsize=11)\n",
    "        plt.yticks(fontsize=11)\n",
    "        plt.locator_params(axis='x', nbins=6)\n",
    "        plt.ylabel('Node evaluations per second (NEPS)', fontsize=14)\n",
    "        plt.yscale('log')\n",
    "        if print_legend[i][j]:\n",
    "            plt.legend(loc='center left')\n",
    "        plt.savefig(f'{graphics_dir}/{name}/median_neps_{nfc}.svg')\n",
    "        plt.savefig(\n",
    "            f'{graphics_dir}/{name}/median_neps_{nfc}.png', \n",
    "            dpi=600)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median runtimes for each number of fitness cases,\n",
    "# for each tool, for each function set.\n",
    "median_runtimes = []\n",
    "for t, tool in enumerate(tools):\n",
    "    median_runtimes.append([])\n",
    "    for i, _ in enumerate(function_sets.items()):\n",
    "        median_runtimes[-1].append([])\n",
    "        for j, nfc in enumerate(num_fitness_cases):\n",
    "            median_runtimes[-1][-1].append([])\n",
    "            median_runtimes[-1][-1][-1] = np.median(\n",
    "                med_med_avg_runtimes[t][i][j])\n",
    "median_runtimes = np.asarray(median_runtimes)\n",
    "\n",
    "print(f'Median runtimes:\\n{median_runtimes}\\n')\n",
    "print(f'Median runtimes shape:\\n{median_runtimes.shape}\\n')\n",
    "\n",
    "# Total median runtimes for each fitness case threshold,\n",
    "# for each tool.\n",
    "total_median_runtimes = np.asarray(\n",
    "    [[np.sum(median_runtimes[t, :, :n+1])\n",
    "        for n, _ in enumerate(num_fitness_cases)] \n",
    "            for t, _ in enumerate(tools)])\n",
    "\n",
    "print(f'\\nTotal median runtimes:\\n{total_median_runtimes}\\n')\n",
    "print(f'\\nTotal median runtimes shape:\\n{total_median_runtimes.shape}\\n')\n",
    "\n",
    "num_nodes = np.asarray(num_nodes)\n",
    "print(f'\\nNum nodes:\\n{num_nodes}\\n')\n",
    "print(f'\\nNum nodes shape:\\n{num_nodes.shape}\\n')\n",
    "\n",
    "# Total number of program nodes across all function sets,\n",
    "# for each fitness case threshold.\n",
    "total_nodes = np.asarray(\n",
    "    [np.sum([fc * num_nodes for fc in num_fitness_cases[:n+1]])\n",
    "        for n, _ in enumerate(num_fitness_cases)])\n",
    "\n",
    "print(f'\\nTotal nodes:\\n{total_nodes}\\n')\n",
    "print(f'\\nTotal nodes shape:\\n{total_nodes.shape}\\n')\n",
    "\n",
    "# Total median NEPS for each fitness case threshold, for each tool.\n",
    "total_neps = total_nodes / total_median_runtimes\n",
    "\n",
    "print(f'\\nTotal NEPS:\\n{total_neps}\\n')\n",
    "print(f'\\nTotal NEPS shape:\\n{total_neps.shape}\\n')\n",
    "\n",
    "# Average FPGA speedup for each fitness case threshold.\n",
    "avg_fpga_speedup = total_neps[-1, :] / total_neps[:-1, :]\n",
    "\n",
    "print(f'\\nAverage FPGA Speedup:\\n{avg_fpga_speedup}\\n')\n",
    "print(f'\\nAverage FPGA Speedup shape:\\n{avg_fpga_speedup.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('conference-eurogp-2023')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf7eeb66edbff3266b41e4e2ae2471ecfce9d674a073d4959090a8035ad91837"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
